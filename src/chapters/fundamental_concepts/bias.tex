\section{Bias}

\subsection*{Definition of Bias}
In machine learning, \textbf{bias} refers to the error introduced by approximating a complex real-world problem with a simplified model. Bias occurs when a model makes consistent but inaccurate assumptions about the data, leading to systematic errors. High bias typically results in \textbf{underfitting}, where the model fails to capture the complexity of the data.

\subsection*{Types of Bias}
\begin{enumerate}
    \item \textbf{Algorithmic Bias}:
    \begin{itemize}
        \item Occurs due to inherent assumptions in the model, such as linear relationships in linear regression.
        \item Example: Using a linear model for data with a quadratic relationship.
    \end{itemize}
    \item \textbf{Data Bias}:
    \begin{itemize}
        \item Arises from biases present in the data itself, such as unrepresentative samples or imbalanced datasets.
        \item Example: A model trained on data from one demographic may perform poorly on another.
    \end{itemize}
    \item \textbf{Confirmation Bias}:
    \begin{itemize}
        \item Occurs when a model or its designers focus on specific patterns or outcomes, ignoring evidence that contradicts these patterns.
        \item Example: Designing a model to confirm pre-existing beliefs.
    \end{itemize}
    \item \textbf{Selection Bias}:
    \begin{itemize}
        \item Happens when the data used for training is not representative of the real-world data the model will encounter.
        \item Example: Using data from urban areas only to train a model meant for both urban and rural areas.
    \end{itemize}
\end{enumerate}

\subsection*{Causes of Bias}
\begin{itemize}
    \item \textbf{Overly Simplistic Models}: Models that lack the complexity to capture the data's structure (e.g., linear models for non-linear data).
    \item \textbf{Insufficient Features}: Using features that do not provide enough information to make accurate predictions.
    \item \textbf{Incomplete or Skewed Data}: Training data that is not diverse or representative.
    \item \textbf{Faulty Assumptions}: Incorrect assumptions about the data, such as assuming independence between features when they are correlated.
\end{itemize}

\subsection*{Effects of Bias}
\begin{itemize}
    \item \textbf{Underfitting}: The model cannot capture the patterns in the training data, leading to poor performance on both training and test data.
    \item \textbf{Systematic Errors}: Predictions are consistently off in a particular direction.
    \item \textbf{Reduced Generalization}: The model fails to perform well on unseen data due to incorrect assumptions.
\end{itemize}

\subsection*{Measuring Bias}
Bias can be measured using error analysis:
\begin{itemize}
    \item \textbf{Training Error}: High training error often indicates high bias, as the model cannot even fit the training data.
    \item \textbf{Learning Curves}: A flat learning curve with high error on both training and validation data suggests high bias.
    \item \textbf{Metrics}: High bias typically results in low values for performance metrics (e.g., accuracy, F1-score).
\end{itemize}

\subsection*{Techniques to Reduce Bias}
\begin{enumerate}
    \item \textbf{Increase Model Complexity}:
    \begin{itemize}
        \item Use more sophisticated algorithms (e.g., from linear regression to decision trees or neural networks).
        \item Increase the number of parameters or layers in the model.
    \end{itemize}
    \item \textbf{Use More Informative Features}:
    \begin{itemize}
        \item Engineer new features that better capture the underlying patterns in the data.
        \item Use domain knowledge to identify missing or relevant features.
    \end{itemize}
    \item \textbf{Obtain Better Quality Data}:
    \begin{itemize}
        \item Collect more representative and diverse datasets to avoid skewed patterns.
        \item Address data imbalances using techniques like oversampling, undersampling, or synthetic data generation.
    \end{itemize}
    \item \textbf{Relax Model Assumptions}:
    \begin{itemize}
        \item Avoid models with restrictive assumptions, such as linear models for non-linear data.
        \item Use kernel methods or ensemble techniques to capture non-linear relationships.
    \end{itemize}
    \item \textbf{Hyperparameter Tuning}:
    \begin{itemize}
        \item Adjust hyperparameters such as learning rate, regularization strength, or tree depth to reduce systematic errors.
    \end{itemize}
    \item \textbf{Use Ensemble Methods}:
    \begin{itemize}
        \item Combine multiple models (e.g., bagging or boosting) to reduce individual model biases.
    \end{itemize}
    \item \textbf{Regular Model Evaluation}:
    \begin{itemize}
        \item Continuously validate the model on diverse test data to identify and address bias early.
    \end{itemize}
\end{enumerate}

\subsection*{Bias-Variance Tradeoff}
Bias is one side of the \textbf{bias-variance tradeoff}:
\begin{itemize}
    \item \textbf{High Bias (Underfitting)}: Simplistic models with high training and test errors.
    \item \textbf{High Variance (Overfitting)}: Complex models that fit the training data perfectly but fail to generalize.
    \item The goal is to find an optimal balance where bias and variance are minimized.
\end{itemize}

\subsection*{Real-World Examples of Bias}
\begin{itemize}
    \item \textbf{Facial Recognition Systems}: Models trained primarily on one demographic may fail to recognize faces from other demographics (data bias).
    \item \textbf{Loan Approval Models}: Assumptions about financial history can lead to systematic discrimination against certain groups.
    \item \textbf{Medical Diagnosis Models}: Lack of diverse training data can result in models that work well for one population but poorly for others.
\end{itemize}

\subsection*{Conclusion}
Bias is a fundamental challenge in machine learning that impacts model accuracy and generalizability. While some level of bias is unavoidable, it can be mitigated by using more complex models, better data, and systematic evaluation. Understanding and addressing bias is essential for building robust, fair, and effective machine learning systems.
